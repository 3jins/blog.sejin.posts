LSTM-RNN (Long Short-Term Memory - Recurrent Neural Network) 학습모델에 developmental training을 접목시켜서 LSTM-RNN 모델이 input으로 주어지는 데이터의 맥락을 좀 더 잘 이해할 수 있도록 도와보자는 연구주제입니다. 여기서 developmental training이란 겉보기에 거창해보이지만, 학습모델을 조금씩 잘라서 먼저 학습시킨 뒤, 다시 합쳐서 학습시켜보는 방식을 의미합니다. 

학습데이터로는 [IMDb](https://www.imdb.com/)라는 유명 영화리뷰사이트의 [리뷰(data)와 평점(label) 셋](http://ai.stanford.edu/~amaas/data/sentiment/)을 사용했고, 예측 결과는 평점의 범위에 따라 긍정과 부정의 둘로 나오게끔 했습니다. 

### 기술명세

- 개발기간: 2018년 9월 ~ 2018년 11월 5일
- 기술스택
    - Neural Network
        - Python 3.6
        - PyTorch, gensim.word2vec, Tensorboard
    - Web
        - Koa.js, MariaDB, jQuery

### 개발배경

건국대학교 졸업작품 주제입니다. 팀원은 다 정해놓고 주제를 못 정해서 방황하다가 결국 교수님이 제안한 주제로 교수님의 지도 하에 진행한 프로젝트입니다. 

### 프로그램 상세

| <img src="https://raw.githubusercontent.com/3jins/Images/master/drnn-model-layers.png" width="50%"/> |
| :----------------------------------------------------------: |
|                   학습모델의 기본적인 구조                   |

전체적인 구조는 위 그림과 같습니다. 제가 주로 맡은 부분은 저 중에서 Input을 Embedding Layer로 넘기기 전에 해당하는 Embedding 부분이었습니다(사실 저 부분도 친구가 구조를 거의 다 짜서 숟가락만 얹었습니다). 사실상 코드 내용에 관한 설명이 곧 PyTorch로 LSTM 모델을 구현하는 설명과 비슷하므로 이 [시리즈](https://enhanced.kr/postviewer/1551)의 목차를 읽어보시면 저희가 어떤 코드를 구현했는지 대강 감이 오실 것 같습니다. 상세한 코드는 [깃헙](https://github.com/NineDegis/D-RNN)에서 확인해보실 수 있습니다.

음.. 그리고 웹은 막판에 3일 정도 급하게 짠거지만 저의 수고가 아까우니 스크린샷이라도 첨부하겠습니다.

| <img src="https://raw.githubusercontent.com/3jins/Images/master/drnn-frontend.png" width="50%"/> |
| :----------------------------------------------------------: |
| ~~전시회 때 자꾸 보는 사람마다 넷플릭스라 그러던데 넷플릭스 아닙니다.~~ |

### 의의

팀원 중에서 인공신경망에 대해 제대로 아는 사람이 [한 명](https://github.com/poqw) 밖에 없어서 초반에 많이 방황했지만, 결국 팀원 모두가 우리가 무엇을 하고 있는지 제대로 이해하고 맡은 바를 잘 해냈습니다. 결국 저희 팀의 핵심이었던 연구 부분은 시간의 부족으로 제대로 진행되지 못했지만, 졸업작품 심사에서 연구 주제라는 점이 가산의 요인으로 작용했는지 상위 13개 팀에 선정되어 상을 받는 기염을 토하기까지 했습니다(하지만 팀원 4명 중 3명이 면접과 회사 일 때문에 본선 전시회 부스를 지킬 수 없었고, 우리 스스로가 상을 타기에 부끄러운 수준임을 알고 있었기에 입상을 포기하여 다른 팀이 추가선발되었습니다).

본 프로젝트에서 배운 점은 크게 3가지로 나눌 수 있습니다.

1. 인공신경망

    아주 멀지 않은 미래에 현존하는 거의 모든 직업(개발자 포함)이 인공지능으로 대체될 것이라는 전망이 있습니다. 솔직히 겨우 인공신경망 가지고 강인공지능에 필적하는 프로그램을 만들어서 프로그램 개발 같은 일까지 대체할 것 같지는 않지만, 어쨌든 지금 인공지능은 업계에서 매우 핫한 주제고, 그 중에서 인공신경망은 대세를 차지하고 있는 게 사실입니다. 비록 제가 주력분야로 삼은 건 웹이지만, 현 시대의 개발자가 인공신경망과 부딪히지 않고 살아가는 건 어려울 것이라 생각합니다. 그런 의미에서 인공신경망에 대한 전반적인 개념을 잡고, LSTM-RNN 모델을 직접 사용해 본 것은 의미 있는 경험일 것입니다.

2. 협업 프로세스

    매번 코드의 변경 사항이 생길 때마다 pull request를 보내고 팀원 중 1명 이상이 코드리뷰를 했습니다. 완벽한 방법은 아닐 수 있었겠지만 이제 깃으로 좀 협업 구실을 하는 프로세스를 진행할 수 있게 되어 좋습니다.

3. 개발과정에서 새로운 것을 습득하는 방법

    저보다 구글링이 약 30배 정도 빠른 친구에게 받은 조언입니다. 어떤 지식이 필요할 때 그 지식에 관련된 모든 컨텍스트까지 이해하는 건 오버헤드가 심하기 때문에 그 지식을 활용해 해결하고자 하는 task가 무엇인가에 집중해야 함을 알게 됐습니다. 당장 수행해야 하는 task와 관계 없는 지식은 굳이 얻을 필요가 없습니다.

### 아쉬웠던 점

무엇보다 기한이 너무 짧았습니다. 원래 3개월의 시간이 주어져있었고 담당 교수님께서도 그걸 감안해서 제안해주신 주제였는데, 중간에 갑작스럽게 전자과와 졸업전시회를 합동개최하는 것으로 학과방침이 바뀌면서 전시회까지의 일정이 한 달이나 당겨져버렸습니다. 그로 인해 본격적인 연구주제에는 거의 진입하지 못하고 연구주제를 위한 세팅 정도만 하다 끝나버려 아쉽습니다. ~~사실 빨리 자유의 몸이 된 덕에 놀 시간이 많아져서 좋았습니다.~~ 17년도까지 졸업작품을 진행했던 팀들은 초반 2개월 동안 취업준비와 졸업작품 진행을 병행하다가 취업 공고가 거의 올라오지 않는 11월에 본격적으로 졸업작품 개발에 착수했는데, 올해는 졸업전시회 끝나니 웬만한 회사들 면접까지 다 끝나버려서 이런 비효율이 있나 싶을 정도입니다.

그래도 애초 목표였던 '작품은 망하더라도 쓸데없는 프로젝트로 시간 낭비하지 말고 뭐라도 배워가자'라는 목적이 달성되었고, 작품 망한 것도 교수님들이 잘 눈치를 못 채셨는지 전시회 때 좋은 평가를 받았으니 결과적으로 나쁘지 않았습니다.